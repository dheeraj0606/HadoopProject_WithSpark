This page lists all of the examples.

*********************************************************************

#### Notebooks

- Connect to BigSQL from Spark (e.g. on Data Science Experience) [[BigSQL](./notebooks/BigSQL.ipynb)]
- Connect to WebHDFS from Spark (e.g. on Data Science Experience) [[WebHDFS](./notebooks/WebHDFS.ipynb)]


*********************************************************************

#### Ambari

- Performs HDFS service check via Ambari REST api using Groovy [[Ambari](./Ambari/README.md)]
- Lists installed services via Ambari REST api using Groovy [[Ambari](./Ambari/README.md)]
- Shows the hostname for BIGSQL, HIVE, KNOX and BIGR services where the master component runs via Ambari REST api using Groovy [[Ambari](./Ambari/README.md)]

*********************************************************************

#### Big SQL

- Connects to Big SQL via JDBC using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Export table to CSV file using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Create and query external table to HDFS using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Federation to DashDB using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Create and query HBASE table using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Insert and query table using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Load from file and query table using Groovy [[BigSQLGroovy](./BigSQLGroovy/README.md)]
- Connects to Big SQL via JDBC using Java [[BigSQLJava](./BigSQLJava/README.md)]

*********************************************************************

#### HBase

- Connects to HBase and check system version, cluster version and status using Groovy [[HBaseGroovy](./HBaseGroovy/README.md)]
- Manipulate schema and execute CRUD operation using Groovy [[HBaseGroovy](./HBaseGroovy/README.md)]
- Connects to HBase and check system version, cluster version and status using Java [[HBaseJava](./HBaseJava/README.md)]

*********************************************************************

#### Hdfs

- List directory contents, Create a directory and Upload a file using Groovy [[WebHdfsGroovy](./WebHdfsGroovy/README.md)]
- List directory contents, Create a directory and Upload a file using cURL [[WebHdfsCurl](./WebHdfsCurl/README.md)]

*********************************************************************

#### Hive

- Create and Drop table using Groovy [[HiveGroovy](./HiveGroovy/README.md)]
- Create and Drop table using Java [[HiveJava](./HiveJava/README.md)]
- Start a Hive Beeline Session [[HiveBeeline](./HiveBeeline/README.md)]

*********************************************************************

#### Jsqsh

- Download and configure Jsqsh shell for Big SQL [[Jsqsh](./Jsqsh/README.md)]

*********************************************************************

####  Knox

- Run a knox shell client session [[Knoxshell](./Knoxshell/README.md)]

*********************************************************************

#### Oozie

- Compile a Map/Reduce Java application and submit it to Oozie using Groovy [[OozieWorkflowMapReduceGroovy](./OozieWorkflowMapReduceGroovy/README.md)]
- Compile a Map/Reduce Java application and submit it to Oozie using cURL [[OozieWorkflowMapReduceCurl](./OozieWorkflowMapReduceCurl/README.md)]
- Compile a Spark Java application and submit it to Oozie using Groovy [[OozieWorkflowSparkGroovy](./OozieWorkflowSparkGroovy/README.md)]


*********************************************************************

#### Spark

- Perform a simple word count using Pyspark [[SparkWordCountPython](./SparkWordCountPython/README.md)]
- Perform a simple word count using Scala [[SparkWordCountScala](./SparkWordCountScala/README.md)]
- Spark Streaming MessageHub consumer in Scala [[SparkMessageHubScala](./SparkMessageHubScala/README.md)]
- Spark Streaming MessageHub consumer in Scala running on Yarn [[SparkMessageHubScalaYarn](./SparkMessageHubScalaYarn/README.md)]

*********************************************************************

#### SquirrelSQL

- Download, configure and Run SquirrelSQL [[SquirrelSQL](./SquirrelSQL/README.md)]

*********************************************************************

#### WebHCat/Templeton (Using Knox API)

- Execute a Hive Job using Groovy [[WebHCatGroovy](./WebHCatGroovy/README.md)]
- Execute a MapReduce Job using Groovy  [[WebHCatGroovy](./WebHCatGroovy/README.md)]
- Execute a Pig Job using Groovy [[WebHCatGroovy](./WebHCatGroovy/README.md)]

*********************************************************************

#### Zeppelin

- Install, configure and run Zeppelin. Run Pyspark notebook  [[Zeppelin](./Zeppelin/README.md)]

*********************************************************************

More examples coming soon ...

*********************************************************************
